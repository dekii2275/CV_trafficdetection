"""
Vector Store Service - Quáº£n lÃ½ embeddings vÃ  similarity search
Sá»­ dá»¥ng ChromaDB Ä‘á»ƒ lÆ°u trá»¯ vÃ  truy váº¥n vector embeddings
"""

import chromadb
from sentence_transformers import SentenceTransformer
from typing import List, Dict, Optional
import os
from pathlib import Path

class VectorStoreService:
    """
    Service quáº£n lÃ½ vector database cho RAG chatbot luáº­t giao thÃ´ng
    """
    
    def __init__(
        self,
        collection_name: str = "traffic_laws",
        # ChÃºng ta sáº½ tÃ­nh toÃ¡n Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i bÃªn trong, khÃ´ng tin tÆ°á»Ÿng tham sá»‘ truyá»n vÃ o
        persist_directory: str = None, 
        embedding_model: str = "keepitreal/vietnamese-sbert"
    ):
        self.collection_name = collection_name
        
        # --- FIX QUAN TRá»ŒNG: Tá»± Ä‘á»™ng láº¥y Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i ---
        # 1. XÃ¡c Ä‘á»‹nh vá»‹ trÃ­ file vector_store.py hiá»‡n táº¡i
        current_file_path = Path(__file__).resolve()
        
        # 2. LÃ¹i ra 4 cáº¥p Ä‘á»ƒ vá» thÆ° má»¥c gá»‘c dá»± Ã¡n (app -> services -> rag_services -> file nÃ y)
        # TÃ¹y cáº¥u trÃºc folder cá»§a báº¡n, Ä‘oáº¡n nÃ y sáº½ tÃ¬m vá» thÆ° má»¥c chá»©a folder 'data'
        # Giáº£ sá»­ file nÃ y náº±m á»Ÿ: .../CV_trafficdetection/backend/app/services/rag_services/vector_store.py
        project_root = current_file_path.parent.parent.parent.parent.parent
        
        # 3. Táº¡o Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i Ä‘áº¿n data/chroma_db
        if persist_directory is None:
            # Náº¿u cháº¡y uvicorn á»Ÿ trong backend, ta cáº§n trá» ra ngoÃ i hoáº·c vÃ o Ä‘Ãºng chá»—
            # CÃ¡ch an toÃ n nháº¥t: Táº¡o folder data ngay táº¡i project root
            self.persist_directory = os.path.join(str(project_root), "data", "chroma_db")
        else:
            self.persist_directory = persist_directory

        print(f"ðŸ“‚ Vector DB Absolute Path: {self.persist_directory}")
        
        # Táº¡o thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i
        Path(self.persist_directory).mkdir(parents=True, exist_ok=True)
        
        # --- FIX QUAN TRá»ŒNG: DÃ¹ng PersistentClient ---
        # PersistentClient báº¯t buá»™c ghi dá»¯ liá»‡u xuá»‘ng Ä‘Ä©a cá»©ng
        try:
            self.client = chromadb.PersistentClient(path=self.persist_directory)
        except Exception as e:
            print(f"âš ï¸ Lá»—i khá»Ÿi táº¡o ChromaDB: {e}")
            raise e
        
        # Khá»Ÿi táº¡o hoáº·c láº¥y collection
        try:
            self.collection = self.client.get_or_create_collection(
                name=collection_name,
                metadata={"description": "Vietnamese traffic law embeddings"}
            )
            print(f"âœ… Collection ready: {collection_name} (Docs: {self.collection.count()})")
        except Exception as e:
            print(f"âŒ Error getting collection: {e}")
            raise e
        
        # Load embedding model
        print(f"ðŸ”„ Loading embedding model: {embedding_model}")
        try:
            self.embedding_model = SentenceTransformer(embedding_model)
            print("âœ… Embedding model loaded successfully")
        except Exception as e:
            print(f"âŒ Failed to load embedding model: {e}")
            raise e
    
    def add_documents(
        self,
        documents: List[str],
        metadatas: List[Dict],
        ids: Optional[List[str]] = None
    ) -> None:
        if not documents:
            return
        
        print(f"ðŸ”„ Creating embeddings for {len(documents)} documents...")
        embeddings = self.embedding_model.encode(
            documents,
            show_progress_bar=True,
            convert_to_numpy=True
        ).tolist()
        
        if ids is None:
            ids = [f"doc_{i}_{os.urandom(4).hex()}" for i in range(len(documents))]
        
        self.collection.add(
            documents=documents,
            embeddings=embeddings,
            metadatas=metadatas,
            ids=ids
        )
        print(f"âœ… Added {len(documents)} documents. Total now: {self.collection.count()}")
    
    def search(
        self,
        query: str,
        top_k: int = 5,
        filter_metadata: Optional[Dict] = None
    ) -> List[Dict]:
        query_embedding = self.embedding_model.encode(
            query,
            convert_to_numpy=True
        ).tolist()
        
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            where=filter_metadata
        )
        
        formatted_results = []
        if results['ids']:
            for i in range(len(results['ids'][0])):
                formatted_results.append({
                    "id": results['ids'][0][i],
                    "document": results['documents'][0][i],
                    "metadata": results['metadatas'][0][i],
                    "distance": results['distances'][0][i],
                    "similarity_score": 1 - results['distances'][0][i]
                })
        
        return formatted_results
    
    def delete_collection(self) -> None:
        try:
            self.client.delete_collection(name=self.collection_name)
            print(f"ðŸ—‘ï¸ Deleted collection: {self.collection_name}")
        except:
            pass
    
    def get_collection_info(self) -> Dict:
        return {
            "name": self.collection_name,
            "total_documents": self.collection.count(),
            "persist_directory": self.persist_directory
        }
    
    def reset_and_rebuild(self) -> None:
        self.delete_collection()
        self.collection = self.client.get_or_create_collection(
            name=self.collection_name,
            metadata={"description": "Vietnamese traffic law embeddings"}
        )
        print(f"ðŸ”„ Reset collection: {self.collection_name}")


# Singleton instance
_vector_store = None

def get_vector_store() -> VectorStoreService:
    global _vector_store
    if _vector_store is None:
        _vector_store = VectorStoreService()
    return _vector_store